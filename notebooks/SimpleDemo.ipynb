{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#%matplotlib inline\n",
    "#%matplotlib widget\n",
    "%pylab inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Video as JupyterVideo\n",
    "\n",
    "# start datajoint using local server\n",
    "import datajoint as dj\n",
    "\n",
    "# if using testing database\n",
    "dj.config['database.host'] = '127.0.0.1'\n",
    "dj.config['database.user'] = 'root'\n",
    "dj.config['database.password'] = 'pose'\n",
    "\n",
    "dj.config[\"enable_python_native_blobs\"] = True\n",
    "\n",
    "sys.path.append('..')\n",
    "from pose_pipeline.pipeline import VideoSession, Video, TrackingBbox, OpenPose, CenterHMR\n",
    "from pose_pipeline.pipeline import Subject, PersonBbox, PersonBboxValid, OpenPosePerson\n",
    "\n",
    "# for openpose to work\n",
    "home = os.path.expanduser(\"~\")\n",
    "openpose_python_path = os.path.join(home, 'projects/pose/openpose/build/python')\n",
    "sys.path.append(openpose_python_path)\n",
    "\n",
    "# for center HMR to work\n",
    "centerhmr_python_path = os.path.join(home, 'projects/pose/CenterHMR/src')\n",
    "sys.path.append(centerhmr_python_path)\n",
    "sys.path.append(os.path.join(centerhmr_python_path, 'core'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example analysis of data already imported\n",
    "\n",
    "Visualize the data organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = dj.schema('pose_pipeline')\n",
    "dj.ERD(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First run the basic video analysis (can take a while, and typically will be run outside Jupyter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrackingBbox.populate()   # this is a fairly robust person tracker through time\n",
    "OpenPose.populate()       # perform bottom up keypoint detection\n",
    "CenterHMR.populate()      # perform bottom up mesh regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how much data is in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Video())\n",
    "display(TrackingBbox())\n",
    "display(OpenPose())\n",
    "display(CenterHMR())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually annotate the person of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, identify videos that haven't identified a person to track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrackingBbox - PersonBboxValid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select one and watch it. Note the ID displayed over the person and if it changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_filter = 'filename=\"sling0001_8_6\"'\n",
    "video = (TrackingBbox & video_filter).fetch1('output_video')\n",
    "JupyterVideo(video, width=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note these should be manually entered and must be correct\n",
    "# another data pipeline might know that \"subject X\" was recorded in a\n",
    "# particular video session, so might suggest the right answer.\n",
    "# ideally this would be implemented with a wrapper that is \n",
    "# study specific with appropriate access controls\n",
    "\n",
    "subject_id = 'sling0001'\n",
    "Subject.insert1({'subject_id': subject_id}, skip_duplicates=True)\n",
    "\n",
    "subject_key = (Subject & {'subject_id': subject_id}).fetch1('KEY')\n",
    "video_key = (TrackingBbox & video_filter).fetch1('KEY')\n",
    "\n",
    "key = subject_key.copy()\n",
    "key.update(video_key)\n",
    "\n",
    "# IMPORTANT: this should match the (possibly multiple) IDs shown with the subject in the\n",
    "# video just shown\n",
    "key['keep_tracks'] = [2, 58, 98]\n",
    "\n",
    "PersonBboxValid.insert1(key, skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on this manually annotated track, extract the keypoints associated\n",
    "# with that person\n",
    "PersonBbox.populate(video_filter)\n",
    "OpenPosePerson.populate(video_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = (OpenPosePerson & video_filter).fetch1('output_video')\n",
    "JupyterVideo(video, width=320)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP and Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses_dj = CenterHMR.fetch(as_dict=True)[0]\n",
    "\n",
    "poses = np.asarray([r['params']['body_pose'][0] for r in poses_dj['results']])\n",
    "\n",
    "joint_idx = [0, 3]\n",
    "#poses = pd.DataFrame(poses[:, joint_idx], columns=['RHip', 'RKnee'])\n",
    "\n",
    "poses = pd.DataFrame(poses)\n",
    "\n",
    "poses.plot()\n",
    "#plt.xlim(0, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JupyterVideo(poses_dj['output_video'], width=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = OpenPose.fetch1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pose_pipeline.deep_sort_yolov4.parser import tracking_bounding_boxes\n",
    "\n",
    "tracks = tracking_bounding_boxes('tmpn3mr7jtt.mp4', 'out.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JupyterVideo('out.mp4')\n",
    "#TrackingBbox().populate()\n",
    "\n",
    "display(TrackingBbox())\n",
    "\n",
    "d = (TrackingBbox & 'filename=\"sling0002_30_2\"').fetch1()\n",
    "JupyterVideo(d['output_video'], width=320)\n",
    "\n",
    "tracks = d['tracks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = (CenterHMR & 'filename=\"sling0002_30_2\"').fetch1()\n",
    "JupyterVideo(d['output_video'], width=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = (OpenPose & 'filename=\"sling0002_30_2\"').fetch1()\n",
    "JupyterVideo(d['output_video'], width=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tracks\n",
    "\n",
    "def extract_person_track(tracks, keep_tracks_ids = [1, 3]):\n",
    "    \n",
    "    def process_timestamp(track_timestep):\n",
    "        valid = [t for t in track_timestep if t['track_id'] in keep_tracks_ids]\n",
    "        if len(valid) == 1:\n",
    "            return {'present': True, 'bbox': valid[0]['tlwh']}\n",
    "        else:\n",
    "            return {'present': False, 'bbox': [0.0, 0.0, 0.0, 0.0]}\n",
    "        \n",
    "    return [process_timestamp(t) for t in tracks]\n",
    "\n",
    "main_track = extract_person_track(tracks)\n",
    "\n",
    "LD = main_track\n",
    "dict_lists = {k: [dic[k] for dic in LD] for k in LD[0]}\n",
    "\n",
    "present = np.array(dict_lists['present'])\n",
    "np.array(dict_lists['bbox'])[present]\n",
    "np.where(present)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(TrackingBbox & 'filename=\"sling0002_30_0\"').fetch1('tracks', 'timestamps')[1]\n",
    "\n",
    "from pose_pipeline.pipeline import PersonBboxValid, PersonBbox\n",
    "\n",
    "#[1, 3]\n",
    "\n",
    "key = (TrackingBbox & 'filename=\"sling0002_30_2\"').fetch1('KEY')\n",
    "key['subject_id'] = 'sling0002'\n",
    "key['keep_tracks'] = [1, 3]\n",
    "\n",
    "PersonBboxValid.insert1(key, skip_duplicates=True)\n",
    "PersonBbox.populate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox, frames, keypoints = (PersonBbox * OpenPose).fetch1('bbox', 'frames', 'keypoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bbox[frames[0]])\n",
    "keypoints[100][0]  #.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(keypoints[0][0][:, 0], keypoints[0][0][:, 1], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def keypoints_to_bbox(keypoints, thresh=0.1, min_keypoints=5):\n",
    "    valid = keypoints[:, -1] > thresh\n",
    "    keypoints = keypoints[valid, :-1]\n",
    "    \n",
    "    if keypoints.shape[0] < min_keypoints:\n",
    "        return [0.0, 0.0, 0.0, 0.0]\n",
    "    \n",
    "    bbox = [np.min(keypoints[:, 0]), np.min(keypoints[:, 1]), np.max(keypoints[:, 0]), np.max(keypoints[:, 1])]\n",
    "    bbox = bbox[:2] + [bbox[2] - bbox[0], bbox[3] - bbox[1]]\n",
    "    \n",
    "    return bbox\n",
    "\n",
    "kp_bbox = keypoints_to_bbox(keypoints[0][0])\n",
    "print(kp_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(box1: np.ndarray, box2: np.ndarray, tlhw=False):\n",
    "    \"\"\"\n",
    "    calculate intersection over union cover percent\n",
    "    \n",
    "        :param box1: box1 with shape (N,4)\n",
    "        :param box2: box2 with shape (N,4)\n",
    "        :tlhw: bool if format is tlhw and need to be converted to tlbr\n",
    "        :return: IoU ratio if intersect, else 0\n",
    "    \"\"\"\n",
    "    point_num = max(box1.shape[0], box2.shape[0])\n",
    "    b1p1, b1p2, b2p1, b2p2 = box1[:, :2], box1[:, 2:], box2[:, :2], box2[:, 2:]\n",
    "    \n",
    "    if tlhw:\n",
    "        b1p2 = b1p1 + b1p2\n",
    "        b2p2 = b2p1 + b2p2   \n",
    "\n",
    "    # mask that eliminates non-intersecting matrices\n",
    "    base_mat = np.ones(shape=(point_num,)).astype(float)\n",
    "    base_mat *= np.all(np.greater(b1p2 - b2p1, 0), axis=1)\n",
    "    base_mat *= np.all(np.greater(b2p2 - b1p1, 0), axis=1)\n",
    "    \n",
    "    intersect_area = np.prod(np.minimum(b2p2, b1p2) - np.maximum(b1p1, b2p1), axis=1).astype(float)\n",
    "    union_area = np.prod(b1p2 - b1p1, axis=1) + np.prod(b2p2 - b2p1, axis=1) - intersect_area\n",
    "    intersect_ratio = intersect_area / union_area\n",
    "    \n",
    "    return base_mat * intersect_ratio\n",
    "\n",
    "#IoU(bbox[:1], np.array(kp_bbox)[None, ...], tlhw=True)\n",
    "#IoU(bbox[:1], bbox[:1], tlhw=True)\n",
    "IoU(np.array([[0.75, 0.5, 1.0, 1.0]]), np.array([[0.5, 0.5, 1.0, 1.0], [0.5, 0.5, 1.0, 1.0]]) , tlhw=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IoU(np.array([[0.75, 0.5, 1.0, 1.0]]), np.zeros((0,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def match_keypoints_to_bbox(bbox: np.ndarray, keypoints_list: list, thresh=0.3, num_keypoints=25):\n",
    "    \"\"\" Finds the best keypoints with an acceptable IoU, if present \"\"\"\n",
    "    \n",
    "    empty_keypoints = np.zeros((num_keypoints, 3))\n",
    "    \n",
    "    if len(keypoints_list) == 0:\n",
    "        return empty_keypoints, None\n",
    "    \n",
    "    bbox = np.reshape(bbox, (1, 4))\n",
    "    iou = IoU(bbox, np.array([keypoints_to_bbox(k) for k in keypoints_list]) )\n",
    "    idx = np.argmax(iou)\n",
    "    \n",
    "    if iou[idx] > thresh:\n",
    "        return keypoints_list[idx], idx\n",
    "    \n",
    "    return empty_keypoints, None\n",
    "\n",
    "res = [match_keypoints_to_bbox(bbox[idx], keypoints[idx]) for idx in range(bbox.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = list(zip(*res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = (OpenPose * PersonBboxValid & video_filter).fetch1('KEY')\n",
    "keypoints = (OpenPose & key).fetch1('keypoints')\n",
    "bbox = (PersonBbox & key).fetch1('bbox')\n",
    "\n",
    "#print(keypoints)\n",
    "def keypoints_to_bbox(keypoints, thresh=0.1, min_keypoints=5):\n",
    "    valid = keypoints[:, -1] > thresh\n",
    "    keypoints = keypoints[valid, :-1]\n",
    "\n",
    "    if keypoints.shape[0] < min_keypoints:\n",
    "        return [0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "    bbox = [np.min(keypoints[:, 0]), np.min(keypoints[:, 1]), np.max(keypoints[:, 0]), np.max(keypoints[:, 1])]\n",
    "    bbox = bbox[:2] + [bbox[2] - bbox[0], bbox[3] - bbox[1]]\n",
    "\n",
    "    return bbox\n",
    "\n",
    "def IoU(box1: np.ndarray, box2: np.ndarray, tlhw=False):\n",
    "    \"\"\"\n",
    "    calculate intersection over union cover percent\n",
    "\n",
    "        :param box1: box1 with shape (N,4)\n",
    "        :param box2: box2 with shape (N,4)\n",
    "        :tlhw: bool if format is tlhw and need to be converted to tlbr\n",
    "        :return: IoU ratio if intersect, else 0\n",
    "    \"\"\"\n",
    "    point_num = max(box1.shape[0], box2.shape[0])\n",
    "    b1p1, b1p2, b2p1, b2p2 = box1[:, :2], box1[:, 2:], box2[:, :2], box2[:, 2:]\n",
    "\n",
    "    if tlhw:\n",
    "        b1p2 = b1p1 + b1p2\n",
    "        b2p2 = b2p1 + b2p2   \n",
    "\n",
    "    # mask that eliminates non-intersecting matrices\n",
    "    base_mat = np.ones(shape=(point_num,)).astype(float)\n",
    "    base_mat *= np.all(np.greater(b1p2 - b2p1, 0), axis=1)\n",
    "    base_mat *= np.all(np.greater(b2p2 - b1p1, 0), axis=1)\n",
    "\n",
    "    intersect_area = np.prod(np.minimum(b2p2, b1p2) - np.maximum(b1p1, b2p1), axis=1).astype(float)\n",
    "    union_area = np.prod(b1p2 - b1p1, axis=1) + np.prod(b2p2 - b2p1, axis=1) - intersect_area\n",
    "    intersect_ratio = intersect_area / union_area\n",
    "\n",
    "    return base_mat * intersect_ratio\n",
    "\n",
    "def match_keypoints_to_bbox(bbox: np.ndarray, keypoints_list: list, thresh=0.3, num_keypoints=25):\n",
    "    \"\"\" Finds the best keypoints with an acceptable IoU, if present \"\"\"\n",
    "\n",
    "    empty_keypoints = np.zeros((num_keypoints, 3))\n",
    "\n",
    "    if not keypoints_list or len(keypoints_list) == 0:\n",
    "        return empty_keypoints, -1\n",
    "\n",
    "    bbox = np.reshape(bbox, (1, 4))\n",
    "    iou = IoU(bbox, np.array([keypoints_to_bbox(k) for k in keypoints_list]) )\n",
    "    idx = np.argmax(iou)\n",
    "\n",
    "    if iou[idx] > thresh:\n",
    "        return keypoints_list[idx], idx\n",
    "\n",
    "    return empty_keypoints, -1\n",
    "\n",
    "print(len(keypoints))\n",
    "\n",
    "res = [match_keypoints_to_bbox(bbox[idx], keypoints[idx]) for idx in range(bbox.shape[0])]\n",
    "keypoints, openpose_ids = list(zip(*res)) \n",
    "\n",
    "keypoints = np.array(keypoints)\n",
    "openpose_ids = np.array(openpose_ids)\n",
    "\n",
    "print(keypoints.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks, timestamps = (TrackingBbox & key).fetch1('tracks', 'timestamps')\n",
    "len(tracks)\n",
    "\n",
    "PersonBbox.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = (OpenPose * PersonBboxValid & 'filename=\"sling0002_30_2\"').fetch1('KEY')\n",
    "keypoints = (OpenPose & key).fetch1('keypoints')\n",
    "bbox = (PersonBbox & key).fetch1('bbox')\n",
    "\n",
    "print(bbox.shape)\n",
    "print(len(keypoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video_filename = (Video & key).fetch1('video')\n",
    "video_filename = (OpenPose & key).fetch1('output_video')\n",
    "\n",
    "cap = cv2.VideoCapture(video_filename)\n",
    "w, h = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = w, h = cap.get(cv2.CAP_PROP_FRAME_WIDTH), cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "dsize = (int(w // 2), int(h // 2))\n",
    "print(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_frame(frame, idx, dsize, thresh=0.25):\n",
    "    frame = frame.copy()\n",
    "    cv2.rectangle(frame, \n",
    "                  (int(bbox[idx, 0]), int(bbox[idx, 1])), \n",
    "                  (int(bbox[idx, 2] + bbox[idx, 0]), int(bbox[idx, 3] + bbox[idx, 1])),\n",
    "                  (255, 255, 255), 15)\n",
    "    for i in range(25):\n",
    "        if keypoints[idx, i, -1] > thresh:\n",
    "            cv2.circle(frame, (int(keypoints[idx, i, 0]), int(keypoints[idx, i, 1])), 15,\n",
    "                       (255, 255, 255), -1)\n",
    "            \n",
    "    return cv2.resize(frame, dsize=dsize, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "idx = 0\n",
    "frame = draw_frame(frame, idx, dsize=dsize)\n",
    "plt.imshow(frame[..., ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class OpenPosePerson(dj.Computed):\n",
    "    definition = '''\n",
    "    -> PersonBbox\n",
    "    -> OpenPose\n",
    "    ---\n",
    "    keypoints        : longblob\n",
    "    openpose_ids     : longblob\n",
    "    output_video      : attach@localattach    # datajoint managed video file\n",
    "    '''\n",
    "\n",
    "    def make(self, key):\n",
    "\n",
    "        def keypoints_to_bbox(keypoints, thresh=0.1, min_keypoints=5):\n",
    "            valid = keypoints[:, -1] > thresh\n",
    "            keypoints = keypoints[valid, :-1]\n",
    "            \n",
    "            if keypoints.shape[0] < min_keypoints:\n",
    "                return [0.0, 0.0, 0.0, 0.0]\n",
    "            \n",
    "            bbox = [np.min(keypoints[:, 0]), np.min(keypoints[:, 1]), np.max(keypoints[:, 0]), np.max(keypoints[:, 1])]\n",
    "            bbox = bbox[:2] + [bbox[2] - bbox[0], bbox[3] - bbox[1]]\n",
    "            \n",
    "            return bbox\n",
    "\n",
    "        def IoU(box1: np.ndarray, box2: np.ndarray, tlhw=False):\n",
    "            \"\"\"\n",
    "            calculate intersection over union cover percent\n",
    "            \n",
    "                :param box1: box1 with shape (N,4)\n",
    "                :param box2: box2 with shape (N,4)\n",
    "                :tlhw: bool if format is tlhw and need to be converted to tlbr\n",
    "                :return: IoU ratio if intersect, else 0\n",
    "            \"\"\"\n",
    "            point_num = max(box1.shape[0], box2.shape[0])\n",
    "            b1p1, b1p2, b2p1, b2p2 = box1[:, :2], box1[:, 2:], box2[:, :2], box2[:, 2:]\n",
    "            \n",
    "            if tlhw:\n",
    "                b1p2 = b1p1 + b1p2\n",
    "                b2p2 = b2p1 + b2p2   \n",
    "\n",
    "            # mask that eliminates non-intersecting matrices\n",
    "            base_mat = np.ones(shape=(point_num,)).astype(float)\n",
    "            base_mat *= np.all(np.greater(b1p2 - b2p1, 0), axis=1)\n",
    "            base_mat *= np.all(np.greater(b2p2 - b1p1, 0), axis=1)\n",
    "            \n",
    "            intersect_area = np.prod(np.minimum(b2p2, b1p2) - np.maximum(b1p1, b2p1), axis=1).astype(float)\n",
    "            union_area = np.prod(b1p2 - b1p1, axis=1) + np.prod(b2p2 - b2p1, axis=1) - intersect_area\n",
    "            intersect_ratio = intersect_area / union_area\n",
    "            \n",
    "            return base_mat * intersect_ratio\n",
    "\n",
    "        def match_keypoints_to_bbox(bbox: np.ndarray, keypoints_list: list, thresh=0.3, num_keypoints=25):\n",
    "            \"\"\" Finds the best keypoints with an acceptable IoU, if present \"\"\"\n",
    "            \n",
    "            empty_keypoints = np.zeros((num_keypoints, 3))\n",
    "            \n",
    "            if len(keypoints_list) == 0:\n",
    "                return empty_keypoints, None\n",
    "            \n",
    "            bbox = np.reshape(bbox, (1, 4))\n",
    "            iou = IoU(bbox, np.array([keypoints_to_bbox(k) for k in keypoints_list]) )\n",
    "            idx = np.argmax(iou)\n",
    "            \n",
    "            if iou[idx] > thresh:\n",
    "                return keypoints_list[idx], idx\n",
    "            \n",
    "            return empty_keypoints, None\n",
    "            \n",
    "        res = [match_keypoints_to_bbox(bbox[idx], keypoints[idx]) for idx in range(bbox.shape[0])]\n",
    "        keypoints, openpose_ids = list(zip(*res)) \n",
    "\n",
    "        keypoints = np.array(keypoints)\n",
    "        openpose_ids = np.array(openpose_ids)\n",
    "\n",
    "        key['keypoints'] = keypoints\n",
    "        key['openpose_ids'] = openpose_ids\n",
    "        \n",
    "        # TODO: this should probably be another object with a lot of this code generalized\n",
    "        video_filename = (Video & key).fetch1('video')\n",
    "\n",
    "        cap = cv2.VideoCapture(video_filename)\n",
    "        w, h = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = w, h = cap.get(cv2.CAP_PROP_FRAME_WIDTH), cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "        frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        dsize = (int(w // 2), int(h // 2))\n",
    "\n",
    "        _, fname = tempfile.mkstemp(suffix='.mp4')\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        out = cv2.VideoWriter(fname, fourcc, fps, dsize)\n",
    "\n",
    "        for idx in range(frames):\n",
    "\n",
    "            def draw_frame(frame, idx=idx, dsize=dsize, thresh=0.25):\n",
    "                frame = frame.copy()\n",
    "                cv2.rectangle(frame, \n",
    "                            (int(bbox[idx, 0]), int(bbox[idx, 1])), \n",
    "                            (int(bbox[idx, 2] + bbox[idx, 0]), int(bbox[idx, 3] + bbox[idx, 1])),\n",
    "                            (255, 255, 255), 15)\n",
    "                for i in range(keypoints.shape[1]):\n",
    "                    if keypoints[idx, i, -1] > thresh:\n",
    "                        cv2.circle(frame, (int(keypoints[idx, i, 0]), int(keypoints[idx, i, 1])), 15,\n",
    "                                (255, 255, 255), -1)\n",
    "            \n",
    "                return cv2.resize(frame, dsize=dsize, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "            ret, frame = cap.read()\n",
    "            if not ret or frame is None:\n",
    "                break\n",
    "\n",
    "            outframe = draw_frame(frame)\n",
    "            out.write(outframe)\n",
    "        out.release()\n",
    "        cap.release()\n",
    "\n",
    "        key['output_video'] = fname\n",
    "        self.insert1(key)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
